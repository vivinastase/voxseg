# Module for preparing training labels,
# may also be run directly as a script
# Author: Nick Wilkinson 2021
import argparse

import math
import numpy as np
import pandas as pd

import os
import logging

from voxseg_ import utils

import collections


def get_labels(data: pd.DataFrame, params: dict, rate: int) -> pd.DataFrame:
    '''Function for preparing training labels.

    Args:
        data: A pd.DataFrame containing datatset information and signals -- see docs for prep_data().
        params: a dictionary containing
                    frame_length -- the size of the input to the CNN, 
                    nfilt -- number of filters for logfbank
                    winlen -- size of the window for logfbank
                    winstep -- step for logfbank 
        rate (optional): Sample rate. Default is 16k.

    Returns:
        A pd.DataFrame containing labels and metadata.
    '''

    data = data.copy()
    print('------------ Generating training labels -----------')
    data['labels'] = data.apply(lambda x: _generate_label_sequence(x, params, rate), axis=1)
    #data = data.drop(['signal', 'labels'], axis=1)
    data = data.dropna().reset_index(drop=True)
     
    print_label_stats(data['labels'])
    return data


def get_mat_labels(data: pd.DataFrame, params: dict) -> pd.DataFrame:
    '''Function for preparing training labels.

    Args:
        data: A pd.DataFrame containing the processed signal
        params: a dictionary containing
                    frame_length -- the size of the input to the CNN, 
                    nfilt -- number of filters for logfbank
                    winlen -- size of the window for logfbank
                    winstep -- step for logfbank 

    Returns:
        A pd.DataFrame containing labels and metadata.
    '''

    data = data.copy()
    print('------------ Generating training labels -----------')
    data['labels'] = data.apply(lambda x: _generate_mat_label_sequence(x, params), axis=1)
    
    #data = data.drop(['signal', 'labels'], axis=1)
    data = data.dropna().reset_index(drop=True)
    print_label_stats(data['labels'])

    return data



def print_label_stats(pd_labels):
        
    list = []
    for _id, labels in pd_labels.iteritems():
        if labels is not None:
            list.extend(labels)
    
    occurrences = collections.Counter(list)
    logging.info("Label statistics: {}".format(occurrences))
    

def one_hot(col: pd.Series) -> pd.Series:
    '''Function for converting string labels to one-hot encoded labels. One-hot mapping is done
    in alphabetical order of sting labels eg. {a: [1, 0, 0], b = [0, 1, 0], c = [0, 0, 1]}.

    Args:
        col: A column of a pd.DataFrame containing label sequences generated by get_labels().

    Returns:
        A pd.Series containing the label sequences converted to one-hot encoding.
    '''

    unique = np.unique(np.hstack(col))
    label_map = {}
    for n, i in enumerate(unique):
        temp = np.zeros(len(unique))
        temp[n] = 1
        label_map[i] = temp
    return col.apply(lambda x: np.array([label_map[i] for i in x]))


def prep_data(path: str, params):
    '''Function for creating pd.DataFrame containing dataset information specified by Kaldi-style
    data directory containing 'wav.spc', 'segments' and 'utt2spk'.

    Args:
        data_dir: The path to the data directory.
        params: signal processing parameters

    Returns:
        A pd.DataFrame of dataset information. For example:

            recording-id  extended filename        utterance-id  start  end  label       signal
        0   rec_00        ~/Documents/test_00.wav  utt_00        10     20   speech      [-49, -43, -35...
        1   rec_00        ~/Documents/test_00.wav  utt_01        50     60   non_speech  [-35, -23, -12...
        2   rec_01        ~/Documents/test_01.wav  utt_02        135    163  speech      [25, 32, 54...
    '''

    wav_scp, segments, utt2spk = utils.process_data_dir(path, params)
    assert utt2spk is not None and segments is not None, \
        'ERROR: Data directory needs to contain \'segments\' and \'utt2spk\'\
            containing label information.'
    data = wav_scp.merge(segments).merge(utt2spk)
    data = data.rename(columns={"speaker-id": "labels"})
    (rate, pd_data) = utils.read_sigs(data)
    data = data.merge(pd_data)
    return (rate, data)


def _generate_label_sequence(row: pd.DataFrame, params: dict, rate: int) -> np.ndarray:
    '''Auxiliary function used by get_labels(). Generated label arrays from a row of a pd.DataFrame
    containing dataset information created by prep_data().

    Args:
        row: A row of a pd.DataFrame created by prep_data().        
        params: a dictionary containing
                    frame_length -- the size of the input to the CNN, 
                    nfilt -- number of filters for logfbank
                    winlen -- size of the window for logfbank
                    winstep -- step for logfbank 
        rate: Sample rate.

    Returns:
        An np.ndarray of labels.
    '''

    sig = row['signal']
    if 'utterance-id' in row:
        id = row['utterance-id']
    else:
        id = row['recording-id']
    try:
        interval_length = utils.get_interval_length(rate, params)
        len_sig = len(sig)

        assert len(range(0, len_sig-1-interval_length, interval_length)) > 0
        labels = []
        end = 0
        
        for _ in utils.progressbar(range(0, len_sig-1-interval_length, interval_length), id):
            labels.append(row['labels'])
            end += interval_length
            
        ## for the last incomplete interval
        if end < len_sig-1:
            labels.append(row['labels'])
               
        return np.array(labels)
    
    except AssertionError:
        pass
    



def _generate_mat_label_sequence(row: pd.DataFrame, params: dict) -> np.ndarray:
    '''Auxiliary function used by get_labels(). Generated label arrays from a row of a pd.DataFrame
    containing dataset information created by prep_data().

    Args:
        row: A row of a pd.DataFrame created by prep_data().        
        params: a dictionary containing
                    frame_length -- the size of the input to the CNN, 
                    nfilt -- number of filters for logfbank
                    winlen -- size of the window for logfbank
                    winstep -- step for logfbank 

    Returns:
        An np.ndarray of labels.
    '''

    sig = row['signal']
    if 'utterance-id' in row:
        id = row['utterance-id']
    else:
        id = row['recording-id']
    try:
        (interval_length, winstep) = utils.get_mat_interval_length(params) ## to make overlapping frames 
        len_sig = len(sig)
        assert len(range(0, len_sig-1-interval_length, interval_length)) > 0
        labels = []
        end = 0
        for j in utils.progressbar(range(0, len_sig-1-interval_length, winstep), id):
            labels.append(row['labels'])
            end = j + interval_length
                          
        if end < len_sig-1:
            labels.append(row['labels'])
        
        return np.array(labels)
    except AssertionError:
        pass
    
    

# Handle args when run directly
if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='prep_labels.py',
                                     description='Prepare labels for model training.')

    parser.add_argument('data_dir', type=str,
                        help='a path to a Kaldi-style data directory containting \'wav.scp\', \'segments\', and \'utt2spk\'')
    
    parser.add_argument('out_dir', type=str,
                        help='a path to an output directory where labels and metadata will be saved as labels.h5')

    parser.add_argument('-f', '--frame_length', type=float, default=32,
                        help='the frame length to consider (originally was defaulted to 0.32 -- smaller values have an impact on the CNN architecture -- the information gets compressed quickly and it cannot pass through 3 layers')
    
    parser.add_argument('-n', '--nfilt', type=int, default=32,
                        help='the number of filters to extract from the signal data -- will be one of the dimensions of the input to the CNN (nfilt x frame-length (as array length))')

    parser.add_argument('-l', '--winlen', type=float, default=0.025,
                        help='the window length parameter for extracting features from the signal data with logfbank')

    parser.add_argument('-w', '--winstep', type=float, default=0.01,
                        help='the window step parameter for extracting features with logfbank (which determines how much the windows from which features are extracted overlap)')


    args = parser.parse_args()

    params = {"frame_length": args.frame_length, "nfilt": args.nfilt, "winlen": args.winlen, "winstep": args.winstep}
    
    (rate, data) = prep_data(args.data_dir)
    labels = get_labels(data, params, rate)
    labels['labels'] = one_hot(labels['labels'])
    
    if not os.path.exists(args.out_dir):
        print(f'Directory {args.out_dir} does not exist, creating it.')
        os.mkdir(args.out_dir)
    utils.save(labels, f'{args.out_dir}/labels.h5')